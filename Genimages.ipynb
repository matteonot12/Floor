{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**This script generates 500 augmented images from clean image**"
      ],
      "metadata": {
        "id": "MfDIAQP8yV6o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8elIK8uhsTeV"
      },
      "outputs": [],
      "source": [
        "!pip install albumentations\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load the reference image\n",
        "image_path = 'Interieur.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Load the floor mask and ensure it's of the same size as the image being processed\n",
        "floormask_path = 'Floormask.png'\n",
        "floormask_image = cv2.imread(floormask_path, cv2.IMREAD_UNCHANGED)  # Ensure we read the alpha channel\n",
        "floormask_resized = cv2.resize(floormask_image, (image.shape[1], image.shape[0]))\n",
        "\n",
        "# Enhanced augmentation pipeline\n",
        "augment = A.Compose([\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.CLAHE(p=0.3),\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=5, p=0.5),\n",
        "    A.GaussianBlur(p=0.3),\n",
        "    A.MotionBlur(blur_limit=3, p=0.3),\n",
        "    A.GaussNoise(p=0.3),\n",
        "    A.ISONoise(p=0.3),\n",
        "    A.HueSaturationValue(hue_shift_limit=15, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
        "    A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), angle_lower=0, angle_upper=1, num_flare_circles_lower=3, num_flare_circles_upper=8, p=0.5),\n",
        "    A.RandomGamma(gamma_limit=(80, 120), p=0.5)\n",
        "])\n",
        "\n",
        "# Create an 'output' directory for the augmented images\n",
        "output_dir = 'output2'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Apply augmentations and save 500 augmented images\n",
        "for i in range(500):\n",
        "    augmented_image = augment(image=image)['image']\n",
        "\n",
        "    # Mask the augmented image using the floor mask\n",
        "    masked_image = cv2.bitwise_and(augmented_image, augmented_image, mask=floormask_resized[:,:,3])  # Using the alpha channel of the mask\n",
        "\n",
        "    save_path = os.path.join(output_dir, f\"augmented_{i}.jpg\")\n",
        "    cv2.imwrite(save_path, cv2.cvtColor(masked_image, cv2.COLOR_RGB2BGR))\n"
      ],
      "metadata": {
        "id": "loCc3LSB9N3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This script generates 500 dirty and cleann images from clean images**"
      ],
      "metadata": {
        "id": "V2T_9rlqymQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import albumentations as A\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "# Load the reference image\n",
        "image_path = 'Interieur.jpg'\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Load the stain images\n",
        "stain_paths = [f'vlek{i}.png' for i in range(1, 9)]\n",
        "stain_examples = [cv2.cvtColor(cv2.imread(stain_path, cv2.IMREAD_UNCHANGED), cv2.COLOR_BGRA2RGBA) for stain_path in stain_paths]\n",
        "\n",
        "# Load the floor mask\n",
        "floormask_path = 'Floormask.png'\n",
        "floormask_image = cv2.imread(floormask_path, cv2.IMREAD_UNCHANGED)\n",
        "floormask_resized = cv2.resize(floormask_image, (image.shape[1], image.shape[0]))\n",
        "\n",
        "# Get the coordinates of the mask\n",
        "y_indices, x_indices = np.where(floormask_resized[:,:,3] > 0)\n",
        "coordinates = list(zip(y_indices, x_indices))\n",
        "\n",
        "# Enhanced augmentation pipeline\n",
        "augment = A.Compose([\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.CLAHE(p=0.3),\n",
        "    A.RandomShadow(shadow_roi=(0, 0.5, 1, 1), num_shadows_lower=1, num_shadows_upper=2, shadow_dimension=5, p=0.5),\n",
        "    A.GaussianBlur(p=0.3),\n",
        "    A.MotionBlur(blur_limit=3, p=0.3),\n",
        "    A.GaussNoise(p=0.3),\n",
        "    A.ISONoise(p=0.3),\n",
        "    A.HueSaturationValue(hue_shift_limit=15, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
        "    A.RandomSunFlare(flare_roi=(0, 0, 1, 0.5), angle_lower=0, angle_upper=1, num_flare_circles_lower=3, num_flare_circles_upper=8, p=0.5),\n",
        "    A.RandomGamma(gamma_limit=(80, 120), p=0.5)\n",
        "])\n",
        "\n",
        "def overlay_stains_on_mask(image, stain_examples, coordinates, mask):\n",
        "    output_image = image.copy()\n",
        "    for _ in range(random.randint(1, 15)):\n",
        "        stain = random.choice(stain_examples).copy()\n",
        "\n",
        "        # Randomly rotate and scale the stain\n",
        "        rotation_angle = random.randint(0, 360)\n",
        "        scale_factor = random.uniform(0.8, 1.2)\n",
        "        M = cv2.getRotationMatrix2D((stain.shape[1] // 2, stain.shape[0] // 2), rotation_angle, scale_factor)\n",
        "        rotated_stain = cv2.warpAffine(stain, M, (stain.shape[1], stain.shape[0]))\n",
        "\n",
        "        y, x = random.choice(coordinates)\n",
        "\n",
        "        # Adjust to top-left corner of the stain\n",
        "        y = max(y - rotated_stain.shape[0] // 2, 0)\n",
        "        x = max(x - rotated_stain.shape[1] // 2, 0)\n",
        "\n",
        "        h, w, _ = rotated_stain.shape\n",
        "\n",
        "        # Get the overlay area and its dimensions\n",
        "        overlay_area = output_image[y:y+h, x:x+w]\n",
        "        overlay_h, overlay_w, _ = overlay_area.shape\n",
        "\n",
        "        # Adjust the size of the rotated stain and the alpha channel based on the overlay area dimensions\n",
        "        rotated_stain = rotated_stain[:overlay_h, :overlay_w]\n",
        "        alpha = rotated_stain[..., 3] / 255.0\n",
        "        alpha = np.expand_dims(alpha, axis=2)\n",
        "\n",
        "        blended_area = alpha * rotated_stain[..., :3] + (1 - alpha) * overlay_area\n",
        "\n",
        "        output_image[y:y+overlay_h, x:x+overlay_w] = blended_area\n",
        "\n",
        "    # Clear everything outside the floor mask\n",
        "    output_image = cv2.bitwise_and(output_image, output_image, mask=mask[:,:,3])\n",
        "\n",
        "    return output_image\n",
        "\n",
        "\n",
        "\n",
        "# Parallel processing\n",
        "def generate_image(i):\n",
        "    augmented_image = augment(image=image)['image']\n",
        "    masked_image = cv2.bitwise_and(augmented_image, augmented_image, mask=floormask_resized[:,:,3])\n",
        "    stained_image = overlay_stains_on_mask(masked_image, stain_examples, coordinates, floormask_resized)\n",
        "    save_path_clean = os.path.join(output_clean_dir, f\"clean_{i}.jpg\")\n",
        "    save_path_dirty = os.path.join(output_dirty_dir, f\"dirty_{i}.jpg\")\n",
        "    cv2.imwrite(save_path_clean, cv2.cvtColor(masked_image, cv2.COLOR_RGB2BGR))\n",
        "    cv2.imwrite(save_path_dirty, cv2.cvtColor(stained_image, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "# Create 'output_clean' and 'output_dirty' directories\n",
        "output_clean_dir = 'output_clean'\n",
        "output_dirty_dir = 'output_dirty'\n",
        "if not os.path.exists(output_clean_dir):\n",
        "    os.makedirs(output_clean_dir)\n",
        "if not os.path.exists(output_dirty_dir):\n",
        "    os.makedirs(output_dirty_dir)\n",
        "\n",
        "# Use multiprocessing for parallel image generation\n",
        "with Pool(cpu_count()) as p:\n",
        "    p.map(generate_image, range(1000))\n"
      ],
      "metadata": {
        "id": "QD_W-phqfr-v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the images"
      ],
      "metadata": {
        "id": "5CuPUo4GiUCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# Folders to be downloaded\n",
        "folders_to_download = ['/content/output_dirty', '/content/output_clean']\n",
        "\n",
        "# Create a ZIP archive\n",
        "zip_filename = 'downloaded_folders.zip'\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    for folder in folders_to_download:\n",
        "        folder_name = folder.split('/')[-1]\n",
        "        for root, dirs, files in os.walk(folder):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, '/content')\n",
        "                zipf.write(file_path, arcname)\n",
        "\n",
        "# Download the ZIP archive to your PC\n",
        "from google.colab import files\n",
        "files.download(zip_filename)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "b-DCMfBIiTFI",
        "outputId": "6f856b7f-5b0d-4c37-fd2c-ede88cb3ebdb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1ba86d6b-8f2d-4a16-8c55-a4a6521de4cc\", \"downloaded_folders.zip\", 48943363)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove the images"
      ],
      "metadata": {
        "id": "aRWpTDhViXj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# List of folder paths to be deleted\n",
        "folders_to_delete = [\n",
        "    '/content/output_clean',\n",
        "    '/content/output_dirty'\n",
        "]\n",
        "\n",
        "# Loop through the list and delete each folder\n",
        "for folder_path in folders_to_delete:\n",
        "    shutil.rmtree(folder_path)\n",
        "    print(f\"Folder {folder_path} has been deleted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrpxlqULan0n",
        "outputId": "614fcca1-ce55-4dfd-af39-03d5ae3cd4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder /content/output_clean has been deleted.\n",
            "Folder /content/output_dirty has been deleted.\n"
          ]
        }
      ]
    }
  ]
}